{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_model import *\n",
    "from metrics import *\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data process\n",
    "T0 = np.array([\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 0.5]\n",
    "])\n",
    "\n",
    "T1 = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 0],\n",
    "    [0.5, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c82149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find kl loss between model and these processes\n",
    "T0_proc1 = np.array([\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1], \n",
    "    [0, 0, 0.5]\n",
    "])\n",
    "T1_proc1 = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 0],\n",
    "    [0.5, 0, 0]\n",
    "])\n",
    "\n",
    "# Different process\n",
    "'''T0_proc2 = np.array([\n",
    "    [0.3, 0.7, 0],\n",
    "    [0, 0.2, 0.8],\n",
    "    [0.1, 0.1, 0.8]\n",
    "])\n",
    "T1_proc2 = np.array([\n",
    "    [0.2, 0.3, 0.5],\n",
    "    [0.6, 0.4, 0],\n",
    "    [0, 0.8, 0.2]\n",
    "])'''\n",
    "process1 = MarkovData(n_gen=50, gen_len=32, n_states=3, d_vocab=2, T_list=[T0_proc1, T1_proc1], seed=42)\n",
    "#process2 = MarkovData(n_gen=50, gen_len=30, n_states=3, d_vocab=2, T_list=[T0_proc2, T1_proc2], seed=43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3134a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_config = MetricsConfig(\n",
    "    track_markov_kl=True,\n",
    "    markov_processes=[process1],  # Will create markov_kl_proc0, markov_kl_proc1\n",
    "    \n",
    "    \n",
    "    track_ngrams=True,\n",
    "    ngram_orders=[1, 2, 3],\n",
    "    track_previous_token=True,\n",
    "    track_in_context=True, \n",
    "    #icl_data=icl_data,\n",
    "    icl_k1=5,\n",
    "    icl_k2=32,\n",
    "\n",
    "    track_prefix_matching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2924bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MarkovData(10000, 32, 3, 2, [T0, T1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = train_model(\n",
    "    dataset=dataset,\n",
    "    n_layers=2,\n",
    "    d_model=16,\n",
    "    n_heads=2, \n",
    "    attn_only=True,\n",
    "    act_fn='silu',\n",
    "\n",
    "    # Training\n",
    "    n_epochs=300,\n",
    "    batch_size=64,\n",
    "    lr=0.1,\n",
    "\n",
    "    # Logging\n",
    "    wandb=True,\n",
    "    wandb_project_name=\"ICL\",\n",
    "    save_dir=\"proc1/debug/\",\n",
    "    save_every=20,\n",
    "    print_every=10,\n",
    "\n",
    "    # ALL ADVANCED METRICS ENABLED\n",
    "    metrics_config=metrics_config,\n",
    "    metrics_log_interval=20\n",
    "    )\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af915678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"proc1/seq_len_30/model300.pt\",\"proc1/seq_len_30/model_cfg.pt\")\n",
    "logits = model(torch.tensor([[0,1,1,0,1,0,0,1,1,0], \n",
    "                                [1,0,1,1,0,1,0,0,1,1], \n",
    "                                [1,0,0,1,0,0,1,0,0,1]], dtype=torch.int64))\n",
    "print(logits[:, -1])\n",
    "print(logits[:, -1].argmax(dim=-1))\n",
    "\n",
    "# Sample and compare\n",
    "sample, states = dataset.model.sample_sequence(max_new_tokens=32)\n",
    "preds = model(torch.tensor([sample], dtype=torch.int64)).argmax(dim=-1).flatten().tolist()\n",
    "\n",
    "for s, pred in zip(sample[1:], preds[:-1]):\n",
    "    print(f\"Actual: {s}, Predicted: {pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toytrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
