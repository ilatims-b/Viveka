Moving model to device:  cpu
  2%|‚ñè         | 7/300 [00:06<04:38,  1.05it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 1 Samples 8000 Step 124 Training Loss 0.4951874017715454
Epoch 1 Validation Loss 0.49444904923439026
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 2 Samples 8000 Step 124 Training Loss 0.4808131754398346
Epoch 2 Validation Loss 0.48098284006118774
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 3 Samples 8000 Step 124 Training Loss 0.47236090898513794
Epoch 3 Validation Loss 0.4736836850643158
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 4 Samples 8000 Step 124 Training Loss 0.47143858671188354
Epoch 4 Validation Loss 0.4695853590965271
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 5 Samples 8000 Step 124 Training Loss 0.47023922204971313
Epoch 5 Validation Loss 0.46773412823677063
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 6 Samples 8000 Step 124 Training Loss 0.4684675931930542
Epoch 6 Validation Loss 0.4667213261127472
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 7 Samples 8000 Step 124 Training Loss 0.4680662453174591
Epoch 7 Validation Loss 0.4662768840789795
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 8 Samples 8000 Step 124 Training Loss 0.47051918506622314
Epoch 8 Validation Loss 0.4659446179866791
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 9 Samples 8000 Step 124 Training Loss 0.47242701053619385
Epoch 9 Validation Loss 0.46582522988319397
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 300 that is less than the current step 302. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 400 that is less than the current step 403. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 500 that is less than the current step 503. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 600 that is less than the current step 604. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 700 that is less than the current step 705. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 800 that is less than the current step 806. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 900 that is less than the current step 907. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1000 that is less than the current step 1007. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1100 that is less than the current step 1108. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1200 that is less than the current step 1209. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 10 Samples 8000 Step 124 Training Loss 0.4645548164844513
Epoch 10 Validation Loss 0.4654609262943268
  5%|‚ñå         | 16/300 [00:16<04:58,  1.05s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 11 Samples 8000 Step 124 Training Loss 0.46712061762809753
Epoch 11 Validation Loss 0.46609726548194885
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 12 Samples 8000 Step 124 Training Loss 0.4658218026161194
Epoch 12 Validation Loss 0.4651273190975189
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 13 Samples 8000 Step 124 Training Loss 0.4761422574520111
Epoch 13 Validation Loss 0.4653414189815521
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 14 Samples 8000 Step 124 Training Loss 0.4638274312019348
Epoch 14 Validation Loss 0.4645742177963257
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 15 Samples 8000 Step 124 Training Loss 0.46311402320861816
Epoch 15 Validation Loss 0.46471771597862244
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 16 Samples 8000 Step 124 Training Loss 0.4699566960334778
Epoch 16 Validation Loss 0.46411341428756714
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 17 Samples 8000 Step 124 Training Loss 0.46214738488197327
Epoch 17 Validation Loss 0.4638562798500061
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 18 Samples 8000 Step 124 Training Loss 0.4629444181919098
Epoch 18 Validation Loss 0.4637012481689453
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 19 Samples 8000 Step 124 Training Loss 0.46316590905189514
Epoch 19 Validation Loss 0.4633144438266754
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1400 that is less than the current step 1411. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1500 that is less than the current step 1511. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1600 that is less than the current step 1612. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1700 that is less than the current step 1713. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1800 that is less than the current step 1814. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1900 that is less than the current step 1915. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 20 Samples 8000 Step 124 Training Loss 0.47372546792030334
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2000 that is less than the current step 2015. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2100 that is less than the current step 2116. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2200 that is less than the current step 2217. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2300 that is less than the current step 2318. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2400 that is less than the current step 2419. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 20 Validation Loss 0.4630276560783386
  9%|‚ñâ         | 27/300 [00:26<04:12,  1.08it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 21 Samples 8000 Step 124 Training Loss 0.4671732485294342
Epoch 21 Validation Loss 0.4631853997707367
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 22 Samples 8000 Step 124 Training Loss 0.45988762378692627
Epoch 22 Validation Loss 0.4625149369239807
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 23 Samples 8000 Step 124 Training Loss 0.45946812629699707
Epoch 23 Validation Loss 0.46213269233703613
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 24 Samples 8000 Step 124 Training Loss 0.4622753858566284
Epoch 24 Validation Loss 0.46207931637763977
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 25 Samples 8000 Step 124 Training Loss 0.4656306803226471
Epoch 25 Validation Loss 0.4615662097930908
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 26 Samples 8000 Step 124 Training Loss 0.457454115152359
Epoch 26 Validation Loss 0.4621744751930237
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 27 Samples 8000 Step 124 Training Loss 0.4608509838581085
Epoch 27 Validation Loss 0.46164563298225403
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 28 Samples 8000 Step 124 Training Loss 0.46297699213027954
Epoch 28 Validation Loss 0.461296021938324
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 29 Samples 8000 Step 124 Training Loss 0.4550918936729431
Epoch 29 Validation Loss 0.46011024713516235
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 30 Samples 8000 Step 124 Training Loss 0.45259496569633484
Epoch 30 Validation Loss 0.46086177229881287
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2600 that is less than the current step 2620. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2700 that is less than the current step 2721. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2800 that is less than the current step 2822. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2900 that is less than the current step 2923. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3000 that is less than the current step 3023. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3100 that is less than the current step 3124. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3200 that is less than the current step 3225. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3300 that is less than the current step 3326. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3400 that is less than the current step 3427. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3500 that is less than the current step 3527. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3600 that is less than the current step 3628. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3700 that is less than the current step 3729. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 31 Samples 8000 Step 124 Training Loss 0.46607357263565063
Epoch 31 Validation Loss 0.45982441306114197
 12%|‚ñà‚ñè        | 37/300 [00:36<04:20,  1.01it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 32 Samples 8000 Step 124 Training Loss 0.46374985575675964
Epoch 32 Validation Loss 0.46119093894958496
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 33 Samples 8000 Step 124 Training Loss 0.4537859559059143
Epoch 33 Validation Loss 0.4595777988433838
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 34 Samples 8000 Step 124 Training Loss 0.4608686864376068
Epoch 34 Validation Loss 0.4666711986064911
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 35 Samples 8000 Step 124 Training Loss 0.4550817310810089
Epoch 35 Validation Loss 0.4583023190498352
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 36 Samples 8000 Step 124 Training Loss 0.4541895389556885
Epoch 36 Validation Loss 0.4572508931159973
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 37 Samples 8000 Step 124 Training Loss 0.4580936133861542
Epoch 37 Validation Loss 0.46070271730422974
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 38 Samples 8000 Step 124 Training Loss 0.451613187789917
Epoch 38 Validation Loss 0.45622462034225464
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 39 Samples 8000 Step 124 Training Loss 0.4524883031845093
Epoch 39 Validation Loss 0.4574156403541565
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 40 Samples 8000 Step 124 Training Loss 0.4538785219192505
Epoch 40 Validation Loss 0.45475584268569946
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3900 that is less than the current step 3931. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4000 that is less than the current step 4031. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4100 that is less than the current step 4132. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4200 that is less than the current step 4233. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4300 that is less than the current step 4334. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4400 that is less than the current step 4435. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4500 that is less than the current step 4535. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4600 that is less than the current step 4636. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4700 that is less than the current step 4737. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4800 that is less than the current step 4838. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4900 that is less than the current step 4939. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5000 that is less than the current step 5039. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 41 Samples 8000 Step 124 Training Loss 0.45694154500961304
Epoch 41 Validation Loss 0.4582441747188568
 16%|‚ñà‚ñå        | 47/300 [00:46<03:54,  1.08it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 42 Samples 8000 Step 124 Training Loss 0.44635942578315735
Epoch 42 Validation Loss 0.4604606330394745
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 43 Samples 8000 Step 124 Training Loss 0.4576244354248047
Epoch 43 Validation Loss 0.4552166759967804
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 44 Samples 8000 Step 124 Training Loss 0.45782729983329773
Epoch 44 Validation Loss 0.4547543525695801
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 45 Samples 8000 Step 124 Training Loss 0.4472023844718933
Epoch 45 Validation Loss 0.44996675848960876
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 46 Samples 8000 Step 124 Training Loss 0.4523000419139862
Epoch 46 Validation Loss 0.450875461101532
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 47 Samples 8000 Step 124 Training Loss 0.44451019167900085
Epoch 47 Validation Loss 0.4475344717502594
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 48 Samples 8000 Step 124 Training Loss 0.4613277018070221
Epoch 48 Validation Loss 0.45402148365974426
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 49 Samples 8000 Step 124 Training Loss 0.4461601674556732
Epoch 49 Validation Loss 0.4448453187942505
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 50 Samples 8000 Step 124 Training Loss 0.45486125349998474
Epoch 50 Validation Loss 0.4451500475406647
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5200 that is less than the current step 5241. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5300 that is less than the current step 5342. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5400 that is less than the current step 5443. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5500 that is less than the current step 5543. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5600 that is less than the current step 5644. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5700 that is less than the current step 5745. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5800 that is less than the current step 5846. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5900 that is less than the current step 5947. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6000 that is less than the current step 6047. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6100 that is less than the current step 6148. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6200 that is less than the current step 6249. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6300 that is less than the current step 6350. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 51 Samples 8000 Step 124 Training Loss 0.43834036588668823
Epoch 51 Validation Loss 0.44105544686317444
 19%|‚ñà‚ñâ        | 57/300 [00:56<04:09,  1.03s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 52 Samples 8000 Step 124 Training Loss 0.44145193696022034
Epoch 52 Validation Loss 0.43914541602134705
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 53 Samples 8000 Step 124 Training Loss 0.4407154619693756
Epoch 53 Validation Loss 0.43696048855781555
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 54 Samples 8000 Step 124 Training Loss 0.4369705319404602
Epoch 54 Validation Loss 0.43516671657562256
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 55 Samples 8000 Step 124 Training Loss 0.42451342940330505
Epoch 55 Validation Loss 0.4324784576892853
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 56 Samples 8000 Step 124 Training Loss 0.43463370203971863
Epoch 56 Validation Loss 0.4318152666091919
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 57 Samples 8000 Step 124 Training Loss 0.44788995385169983
Epoch 57 Validation Loss 0.4367888271808624
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 58 Samples 8000 Step 124 Training Loss 0.4432048499584198
Epoch 58 Validation Loss 0.43847334384918213
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 59 Samples 8000 Step 124 Training Loss 0.42648106813430786
Epoch 59 Validation Loss 0.42282775044441223
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 60 Samples 8000 Step 124 Training Loss 0.46388065814971924
Epoch 60 Validation Loss 0.45440956950187683
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6500 that is less than the current step 6551. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6600 that is less than the current step 6652. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6700 that is less than the current step 6753. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6800 that is less than the current step 6854. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6900 that is less than the current step 6955. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7000 that is less than the current step 7055. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7100 that is less than the current step 7156. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7200 that is less than the current step 7257. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7300 that is less than the current step 7358. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7400 that is less than the current step 7459. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7500 that is less than the current step 7559. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 61 Samples 8000 Step 124 Training Loss 0.413339227437973
Epoch 61 Validation Loss 0.4274795949459076
 22%|‚ñà‚ñà‚ñè       | 67/300 [01:06<03:41,  1.05it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 62 Samples 8000 Step 124 Training Loss 0.40587693452835083
Epoch 62 Validation Loss 0.41957294940948486
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 63 Samples 8000 Step 124 Training Loss 0.42660844326019287
Epoch 63 Validation Loss 0.43219369649887085
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 64 Samples 8000 Step 124 Training Loss 0.4022587835788727
Epoch 64 Validation Loss 0.4105304181575775
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 65 Samples 8000 Step 124 Training Loss 0.4058382511138916
Epoch 65 Validation Loss 0.410639226436615
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 66 Samples 8000 Step 124 Training Loss 0.42123255133628845
Epoch 66 Validation Loss 0.42815467715263367
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 67 Samples 8000 Step 124 Training Loss 0.40297627449035645
Epoch 67 Validation Loss 0.4071733057498932
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 68 Samples 8000 Step 124 Training Loss 0.3991169333457947
Epoch 68 Validation Loss 0.4022827446460724
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 69 Samples 8000 Step 124 Training Loss 0.42614591121673584
Epoch 69 Validation Loss 0.4205341041088104
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 70 Samples 8000 Step 124 Training Loss 0.3839530050754547
Epoch 70 Validation Loss 0.3953014016151428
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7700 that is less than the current step 7761. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7800 that is less than the current step 7862. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7900 that is less than the current step 7963. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8000 that is less than the current step 8063. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8100 that is less than the current step 8164. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8200 that is less than the current step 8265. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8300 that is less than the current step 8366. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8400 that is less than the current step 8467. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8500 that is less than the current step 8567. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8600 that is less than the current step 8668. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8700 that is less than the current step 8769. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 71 Samples 8000 Step 124 Training Loss 0.3989367187023163
Epoch 71 Validation Loss 0.4067651629447937
 26%|‚ñà‚ñà‚ñå       | 77/300 [01:16<03:59,  1.07s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 72 Samples 8000 Step 124 Training Loss 0.4069983661174774
Epoch 72 Validation Loss 0.41335463523864746
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 73 Samples 8000 Step 124 Training Loss 0.4014429450035095
Epoch 73 Validation Loss 0.4000728726387024
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 74 Samples 8000 Step 124 Training Loss 0.3798983097076416
Epoch 74 Validation Loss 0.38671812415122986
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 75 Samples 8000 Step 124 Training Loss 0.3896799385547638
Epoch 75 Validation Loss 0.3834376335144043
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 76 Samples 8000 Step 124 Training Loss 0.3859378397464752
Epoch 76 Validation Loss 0.39039474725723267
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 77 Samples 8000 Step 124 Training Loss 0.3756158947944641
Epoch 77 Validation Loss 0.3796003758907318
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 78 Samples 8000 Step 124 Training Loss 0.39229410886764526
Epoch 78 Validation Loss 0.38432514667510986
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 79 Samples 8000 Step 124 Training Loss 0.3813066780567169
Epoch 79 Validation Loss 0.378681480884552
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8900 that is less than the current step 8971. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9000 that is less than the current step 9071. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9100 that is less than the current step 9172. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9200 that is less than the current step 9273. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9300 that is less than the current step 9374. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9400 that is less than the current step 9475. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9500 that is less than the current step 9575. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9600 that is less than the current step 9676. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9700 that is less than the current step 9777. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9800 that is less than the current step 9878. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9900 that is less than the current step 9979. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 80 Samples 8000 Step 124 Training Loss 0.37986087799072266
Epoch 80 Validation Loss 0.3796162009239197
 29%|‚ñà‚ñà‚ñâ       | 87/300 [01:26<03:21,  1.06it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 81 Samples 8000 Step 124 Training Loss 0.3719453513622284
Epoch 81 Validation Loss 0.37233784794807434
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 82 Samples 8000 Step 124 Training Loss 0.3877119719982147
Epoch 82 Validation Loss 0.3814897835254669
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 83 Samples 8000 Step 124 Training Loss 0.36445969343185425
Epoch 83 Validation Loss 0.36899957060813904
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 84 Samples 8000 Step 124 Training Loss 0.37360879778862
Epoch 84 Validation Loss 0.36950036883354187
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 85 Samples 8000 Step 124 Training Loss 0.3648827373981476
Epoch 85 Validation Loss 0.3663727939128876
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 86 Samples 8000 Step 124 Training Loss 0.3513159453868866
Epoch 86 Validation Loss 0.36751726269721985
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 87 Samples 8000 Step 124 Training Loss 0.3586500883102417
Epoch 87 Validation Loss 0.36577942967414856
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 88 Samples 8000 Step 124 Training Loss 0.3678043782711029
Epoch 88 Validation Loss 0.3663899004459381
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 89 Samples 8000 Step 124 Training Loss 0.3550722599029541
Epoch 89 Validation Loss 0.36258769035339355
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 90 Samples 8000 Step 124 Training Loss 0.36724570393562317
Epoch 90 Validation Loss 0.36366021633148193
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10100 that is less than the current step 10180. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10200 that is less than the current step 10281. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10300 that is less than the current step 10382. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10400 that is less than the current step 10483. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10500 that is less than the current step 10583. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10600 that is less than the current step 10684. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10700 that is less than the current step 10785. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10800 that is less than the current step 10886. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10900 that is less than the current step 10987. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11000 that is less than the current step 11087. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11100 that is less than the current step 11188. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11200 that is less than the current step 11289. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 91 Samples 8000 Step 124 Training Loss 0.3598094582557678
Epoch 91 Validation Loss 0.36430010199546814
 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [01:37<03:25,  1.01s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 92 Samples 8000 Step 124 Training Loss 0.36738425493240356
Epoch 92 Validation Loss 0.3628966212272644
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 93 Samples 8000 Step 124 Training Loss 0.3599502742290497
Epoch 93 Validation Loss 0.3600229024887085
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 94 Samples 8000 Step 124 Training Loss 0.353735089302063
Epoch 94 Validation Loss 0.3596494495868683
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 95 Samples 8000 Step 124 Training Loss 0.3621281385421753
Epoch 95 Validation Loss 0.36061108112335205
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 96 Samples 8000 Step 124 Training Loss 0.35304293036460876
Epoch 96 Validation Loss 0.3613784611225128
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 97 Samples 8000 Step 124 Training Loss 0.3545311987400055
Epoch 97 Validation Loss 0.35892432928085327
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 98 Samples 8000 Step 124 Training Loss 0.3622437119483948
Epoch 98 Validation Loss 0.3605652451515198
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 99 Samples 8000 Step 124 Training Loss 0.3602885603904724
Epoch 99 Validation Loss 0.35889559984207153
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11400 that is less than the current step 11491. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11500 that is less than the current step 11591. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11600 that is less than the current step 11692. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11700 that is less than the current step 11793. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11800 that is less than the current step 11894. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11900 that is less than the current step 11995. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12000 that is less than the current step 12095. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12100 that is less than the current step 12196. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12200 that is less than the current step 12297. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12300 that is less than the current step 12398. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12400 that is less than the current step 12499. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 100 Samples 8000 Step 124 Training Loss 0.3553292751312256
Epoch 100 Validation Loss 0.35883304476737976
 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [01:46<02:59,  1.08it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 101 Samples 8000 Step 124 Training Loss 0.35476142168045044
Epoch 101 Validation Loss 0.3588733673095703
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 102 Samples 8000 Step 124 Training Loss 0.35880130529403687
Epoch 102 Validation Loss 0.3581952750682831
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 103 Samples 8000 Step 124 Training Loss 0.35017260909080505
Epoch 103 Validation Loss 0.35787367820739746
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 104 Samples 8000 Step 124 Training Loss 0.35686472058296204
Epoch 104 Validation Loss 0.3577593266963959
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 105 Samples 8000 Step 124 Training Loss 0.357645183801651
Epoch 105 Validation Loss 0.362831711769104
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 106 Samples 8000 Step 124 Training Loss 0.36344823241233826
Epoch 106 Validation Loss 0.3596104085445404
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 107 Samples 8000 Step 124 Training Loss 0.353396475315094
Epoch 107 Validation Loss 0.35751381516456604
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 108 Samples 8000 Step 124 Training Loss 0.3358696699142456
Epoch 108 Validation Loss 0.35901764035224915
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 109 Samples 8000 Step 124 Training Loss 0.35226795077323914
Epoch 109 Validation Loss 0.3573774993419647
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 110 Samples 8000 Step 124 Training Loss 0.35495421290397644
Epoch 110 Validation Loss 0.3574122488498688
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12600 that is less than the current step 12700. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12700 that is less than the current step 12801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12800 that is less than the current step 12902. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12900 that is less than the current step 13003. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13000 that is less than the current step 13103. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13100 that is less than the current step 13204. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13200 that is less than the current step 13305. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13300 that is less than the current step 13406. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13400 that is less than the current step 13507. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13500 that is less than the current step 13607. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13600 that is less than the current step 13708. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13700 that is less than the current step 13809. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 111 Samples 8000 Step 124 Training Loss 0.34876370429992676
Epoch 111 Validation Loss 0.36077263951301575
 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [01:56<02:59,  1.02it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 112 Samples 8000 Step 124 Training Loss 0.35411638021469116
Epoch 112 Validation Loss 0.3577806055545807
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 113 Samples 8000 Step 124 Training Loss 0.3524084985256195
Epoch 113 Validation Loss 0.3571678698062897
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 114 Samples 8000 Step 124 Training Loss 0.3557722270488739
Epoch 114 Validation Loss 0.3577536344528198
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 115 Samples 8000 Step 124 Training Loss 0.36139339208602905
Epoch 115 Validation Loss 0.35712844133377075
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 116 Samples 8000 Step 124 Training Loss 0.35473695397377014
Epoch 116 Validation Loss 0.3569597601890564
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 117 Samples 8000 Step 124 Training Loss 0.3525110185146332
Epoch 117 Validation Loss 0.35785216093063354
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 118 Samples 8000 Step 124 Training Loss 0.35581204295158386
Epoch 118 Validation Loss 0.35707715153694153
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 119 Samples 8000 Step 124 Training Loss 0.35063326358795166
Epoch 119 Validation Loss 0.36269545555114746
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 120 Samples 8000 Step 124 Training Loss 0.3584238886833191
Epoch 120 Validation Loss 0.3568226993083954
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13900 that is less than the current step 14011. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14000 that is less than the current step 14111. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14100 that is less than the current step 14212. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14200 that is less than the current step 14313. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14300 that is less than the current step 14414. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14400 that is less than the current step 14515. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14500 that is less than the current step 14615. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14600 that is less than the current step 14716. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14700 that is less than the current step 14817. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14800 that is less than the current step 14918. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14900 that is less than the current step 15019. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15000 that is less than the current step 15119. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 121 Samples 8000 Step 124 Training Loss 0.3515141010284424
Epoch 121 Validation Loss 0.36005985736846924
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [02:06<02:46,  1.04it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 122 Samples 8000 Step 124 Training Loss 0.35879841446876526
Epoch 122 Validation Loss 0.357014000415802
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 123 Samples 8000 Step 124 Training Loss 0.35437294840812683
Epoch 123 Validation Loss 0.3570325970649719
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 124 Samples 8000 Step 124 Training Loss 0.3630915880203247
Epoch 124 Validation Loss 0.3567407429218292
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 125 Samples 8000 Step 124 Training Loss 0.350653737783432
Epoch 125 Validation Loss 0.35679352283477783
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 126 Samples 8000 Step 124 Training Loss 0.3582983613014221
Epoch 126 Validation Loss 0.35655298829078674
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 127 Samples 8000 Step 124 Training Loss 0.3416532874107361
Epoch 127 Validation Loss 0.3590802848339081
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 128 Samples 8000 Step 124 Training Loss 0.35425180196762085
Epoch 128 Validation Loss 0.3588343560695648
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 129 Samples 8000 Step 124 Training Loss 0.3598172664642334
Epoch 129 Validation Loss 0.35655027627944946
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 130 Samples 8000 Step 124 Training Loss 0.35262244939804077
Epoch 130 Validation Loss 0.35728028416633606
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15200 that is less than the current step 15321. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15300 that is less than the current step 15422. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15400 that is less than the current step 15523. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15500 that is less than the current step 15623. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15600 that is less than the current step 15724. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15700 that is less than the current step 15825. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15800 that is less than the current step 15926. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15900 that is less than the current step 16027. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16000 that is less than the current step 16127. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16100 that is less than the current step 16228. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16200 that is less than the current step 16329. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16300 that is less than the current step 16430. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 131 Samples 8000 Step 124 Training Loss 0.36491432785987854
Epoch 131 Validation Loss 0.3583643436431885
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [02:16<02:47,  1.03s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 132 Samples 8000 Step 124 Training Loss 0.3564651906490326
Epoch 132 Validation Loss 0.3567117154598236
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 133 Samples 8000 Step 124 Training Loss 0.3509519696235657
Epoch 133 Validation Loss 0.3573799729347229
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 134 Samples 8000 Step 124 Training Loss 0.35631129145622253
Epoch 134 Validation Loss 0.3565334975719452
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 135 Samples 8000 Step 124 Training Loss 0.3565903902053833
Epoch 135 Validation Loss 0.3563893139362335
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 136 Samples 8000 Step 124 Training Loss 0.3502032458782196
Epoch 136 Validation Loss 0.3577653169631958
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 137 Samples 8000 Step 124 Training Loss 0.35975733399391174
Epoch 137 Validation Loss 0.3565387427806854
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 138 Samples 8000 Step 124 Training Loss 0.3511871099472046
Epoch 138 Validation Loss 0.3576641380786896
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 139 Samples 8000 Step 124 Training Loss 0.3590564727783203
Epoch 139 Validation Loss 0.3572980761528015
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 140 Samples 8000 Step 124 Training Loss 0.36067527532577515
Epoch 140 Validation Loss 0.3578037917613983
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16500 that is less than the current step 16631. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16600 that is less than the current step 16732. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16700 that is less than the current step 16833. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16800 that is less than the current step 16934. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16900 that is less than the current step 17035. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17000 that is less than the current step 17135. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17100 that is less than the current step 17236. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17200 that is less than the current step 17337. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17300 that is less than the current step 17438. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17400 that is less than the current step 17539. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17500 that is less than the current step 17639. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 141 Samples 8000 Step 124 Training Loss 0.35216224193573
Epoch 141 Validation Loss 0.35628655552864075
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [02:26<02:27,  1.04it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 142 Samples 8000 Step 124 Training Loss 0.35432910919189453
Epoch 142 Validation Loss 0.35652995109558105
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 143 Samples 8000 Step 124 Training Loss 0.3641940653324127
Epoch 143 Validation Loss 0.35728999972343445
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 144 Samples 8000 Step 124 Training Loss 0.35339656472206116
Epoch 144 Validation Loss 0.35717061161994934
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 145 Samples 8000 Step 124 Training Loss 0.3541889786720276
Epoch 145 Validation Loss 0.3562658131122589
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 146 Samples 8000 Step 124 Training Loss 0.3513801693916321
Epoch 146 Validation Loss 0.3563905656337738
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 147 Samples 8000 Step 124 Training Loss 0.35623899102211
Epoch 147 Validation Loss 0.3562581539154053
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 148 Samples 8000 Step 124 Training Loss 0.3624260723590851
Epoch 148 Validation Loss 0.35717716813087463
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 149 Samples 8000 Step 124 Training Loss 0.35832029581069946
Epoch 149 Validation Loss 0.35622209310531616
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 150 Samples 8000 Step 124 Training Loss 0.35613587498664856
Epoch 150 Validation Loss 0.35616758465766907
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17700 that is less than the current step 17841. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17800 that is less than the current step 17942. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17900 that is less than the current step 18043. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18000 that is less than the current step 18143. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18100 that is less than the current step 18244. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18200 that is less than the current step 18345. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18300 that is less than the current step 18446. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18400 that is less than the current step 18547. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18500 that is less than the current step 18647. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18600 that is less than the current step 18748. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18700 that is less than the current step 18849. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 151 Samples 8000 Step 124 Training Loss 0.3594757318496704
Epoch 151 Validation Loss 0.35648801922798157
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [02:37<02:27,  1.03s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 152 Samples 8000 Step 124 Training Loss 0.3573818504810333
Epoch 152 Validation Loss 0.3565179705619812
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 153 Samples 8000 Step 124 Training Loss 0.3560771644115448
Epoch 153 Validation Loss 0.3563253581523895
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 154 Samples 8000 Step 124 Training Loss 0.35630157589912415
Epoch 154 Validation Loss 0.3561939299106598
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 155 Samples 8000 Step 124 Training Loss 0.3527866005897522
Epoch 155 Validation Loss 0.35622018575668335
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 156 Samples 8000 Step 124 Training Loss 0.3636028468608856
Epoch 156 Validation Loss 0.35666733980178833
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 157 Samples 8000 Step 124 Training Loss 0.34808844327926636
Epoch 157 Validation Loss 0.35718783736228943
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 158 Samples 8000 Step 124 Training Loss 0.35424816608428955
Epoch 158 Validation Loss 0.3568211495876312
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 159 Samples 8000 Step 124 Training Loss 0.359923392534256
Epoch 159 Validation Loss 0.3569119870662689
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 160 Samples 8000 Step 124 Training Loss 0.3554888069629669
Epoch 160 Validation Loss 0.35621383786201477
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18900 that is less than the current step 19051. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19000 that is less than the current step 19151. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19100 that is less than the current step 19252. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19200 that is less than the current step 19353. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19300 that is less than the current step 19454. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19400 that is less than the current step 19555. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19500 that is less than the current step 19655. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19600 that is less than the current step 19756. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19700 that is less than the current step 19857. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19800 that is less than the current step 19958. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19900 that is less than the current step 20059. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20000 that is less than the current step 20159. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 161 Samples 8000 Step 124 Training Loss 0.35356977581977844
Epoch 161 Validation Loss 0.3570944368839264
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [02:46<02:01,  1.09it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 162 Samples 8000 Step 124 Training Loss 0.3614564836025238
Epoch 162 Validation Loss 0.3564750850200653
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 163 Samples 8000 Step 124 Training Loss 0.3514930009841919
Epoch 163 Validation Loss 0.3563987612724304
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 164 Samples 8000 Step 124 Training Loss 0.33929988741874695
Epoch 164 Validation Loss 0.35788625478744507
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 165 Samples 8000 Step 124 Training Loss 0.3558398187160492
Epoch 165 Validation Loss 0.3561877906322479
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 166 Samples 8000 Step 124 Training Loss 0.3546102046966553
Epoch 166 Validation Loss 0.35612019896507263
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 167 Samples 8000 Step 124 Training Loss 0.3535066545009613
Epoch 167 Validation Loss 0.3562493622303009
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 168 Samples 8000 Step 124 Training Loss 0.3489985764026642
Epoch 168 Validation Loss 0.3566395044326782
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 169 Samples 8000 Step 124 Training Loss 0.3515828549861908
Epoch 169 Validation Loss 0.35661882162094116
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 170 Samples 8000 Step 124 Training Loss 0.34950706362724304
Epoch 170 Validation Loss 0.35634708404541016
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20200 that is less than the current step 20361. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20300 that is less than the current step 20462. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20400 that is less than the current step 20563. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20500 that is less than the current step 20663. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20600 that is less than the current step 20764. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20700 that is less than the current step 20865. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20800 that is less than the current step 20966. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20900 that is less than the current step 21067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21000 that is less than the current step 21167. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21100 that is less than the current step 21268. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21200 that is less than the current step 21369. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 171 Samples 8000 Step 124 Training Loss 0.3481373190879822
Epoch 171 Validation Loss 0.3565021753311157
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [02:56<02:00,  1.02it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 172 Samples 8000 Step 124 Training Loss 0.3511573374271393
Epoch 172 Validation Loss 0.3570297956466675
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 173 Samples 8000 Step 124 Training Loss 0.3475998640060425
Epoch 173 Validation Loss 0.3570599853992462
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 174 Samples 8000 Step 124 Training Loss 0.35634249448776245
Epoch 174 Validation Loss 0.3560713231563568
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 175 Samples 8000 Step 124 Training Loss 0.35689735412597656
Epoch 175 Validation Loss 0.35657912492752075
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 176 Samples 8000 Step 124 Training Loss 0.36117643117904663
Epoch 176 Validation Loss 0.35657188296318054
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 177 Samples 8000 Step 124 Training Loss 0.3485080301761627
Epoch 177 Validation Loss 0.35657140612602234
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 178 Samples 8000 Step 124 Training Loss 0.3561699688434601
Epoch 178 Validation Loss 0.35624679923057556
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 179 Samples 8000 Step 124 Training Loss 0.35256054997444153
Epoch 179 Validation Loss 0.3560962677001953
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 180 Samples 8000 Step 124 Training Loss 0.35775133967399597
Epoch 180 Validation Loss 0.3565311133861542
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21400 that is less than the current step 21571. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21500 that is less than the current step 21671. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21600 that is less than the current step 21772. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21700 that is less than the current step 21873. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21800 that is less than the current step 21974. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21900 that is less than the current step 22075. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22000 that is less than the current step 22175. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22100 that is less than the current step 22276. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22200 that is less than the current step 22377. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22300 that is less than the current step 22478. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22400 that is less than the current step 22579. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22500 that is less than the current step 22679. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 181 Samples 8000 Step 124 Training Loss 0.3602500855922699
Epoch 181 Validation Loss 0.35603591799736023
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [03:05<01:43,  1.09it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 182 Samples 8000 Step 124 Training Loss 0.35307514667510986
Epoch 182 Validation Loss 0.3561912178993225
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 183 Samples 8000 Step 124 Training Loss 0.3545224964618683
Epoch 183 Validation Loss 0.3560466766357422
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 184 Samples 8000 Step 124 Training Loss 0.35955673456192017
Epoch 184 Validation Loss 0.3563399016857147
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 185 Samples 8000 Step 124 Training Loss 0.35425490140914917
Epoch 185 Validation Loss 0.3560856580734253
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 186 Samples 8000 Step 124 Training Loss 0.3473156988620758
Epoch 186 Validation Loss 0.35636720061302185
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 187 Samples 8000 Step 124 Training Loss 0.3461573123931885
Epoch 187 Validation Loss 0.3561471402645111
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 188 Samples 8000 Step 124 Training Loss 0.35770952701568604
Epoch 188 Validation Loss 0.3560962677001953
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 189 Samples 8000 Step 124 Training Loss 0.34557297825813293
Epoch 189 Validation Loss 0.3573867082595825
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 190 Samples 8000 Step 124 Training Loss 0.3587642312049866
Epoch 190 Validation Loss 0.3560599386692047
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 191 Samples 8000 Step 124 Training Loss 0.34910404682159424
Epoch 191 Validation Loss 0.3563433587551117
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22700 that is less than the current step 22881. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22800 that is less than the current step 22982. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22900 that is less than the current step 23083. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23000 that is less than the current step 23183. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23100 that is less than the current step 23284. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23200 that is less than the current step 23385. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23300 that is less than the current step 23486. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23400 that is less than the current step 23587. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23500 that is less than the current step 23687. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23600 that is less than the current step 23788. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23700 that is less than the current step 23889. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23800 that is less than the current step 23990. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 192 Samples 8000 Step 124 Training Loss 0.35483962297439575
Epoch 192 Validation Loss 0.3561188280582428
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [03:17<01:32,  1.09it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 193 Samples 8000 Step 124 Training Loss 0.3461284637451172
Epoch 193 Validation Loss 0.35707512497901917
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 194 Samples 8000 Step 124 Training Loss 0.35541480779647827
Epoch 194 Validation Loss 0.3561643064022064
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 195 Samples 8000 Step 124 Training Loss 0.352791965007782
Epoch 195 Validation Loss 0.3561653792858124
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 196 Samples 8000 Step 124 Training Loss 0.3483889102935791
Epoch 196 Validation Loss 0.35630539059638977
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 197 Samples 8000 Step 124 Training Loss 0.3617818355560303
Epoch 197 Validation Loss 0.3560609519481659
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 198 Samples 8000 Step 124 Training Loss 0.3496841788291931
Epoch 198 Validation Loss 0.3564227819442749
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 199 Samples 8000 Step 124 Training Loss 0.3464395999908447
Epoch 199 Validation Loss 0.3562455475330353
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 200 Samples 8000 Step 124 Training Loss 0.36316192150115967
Epoch 200 Validation Loss 0.35682061314582825
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 201 Samples 8000 Step 124 Training Loss 0.3585539758205414
Epoch 201 Validation Loss 0.35619810223579407
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24000 that is less than the current step 24191. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24100 that is less than the current step 24292. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24200 that is less than the current step 24393. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24300 that is less than the current step 24494. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24400 that is less than the current step 24595. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24500 that is less than the current step 24695. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24600 that is less than the current step 24796. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24700 that is less than the current step 24897. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24800 that is less than the current step 24998. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24900 that is less than the current step 25099. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25000 that is less than the current step 25199. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25100 that is less than the current step 25300. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 202 Samples 8000 Step 124 Training Loss 0.3520559072494507
Epoch 202 Validation Loss 0.35625413060188293
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [03:26<01:34,  1.03s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 203 Samples 8000 Step 124 Training Loss 0.3492765426635742
Epoch 203 Validation Loss 0.3564186692237854
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 204 Samples 8000 Step 124 Training Loss 0.35980236530303955
Epoch 204 Validation Loss 0.356630802154541
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 205 Samples 8000 Step 124 Training Loss 0.36118343472480774
Epoch 205 Validation Loss 0.3569275438785553
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 206 Samples 8000 Step 124 Training Loss 0.3498477637767792
Epoch 206 Validation Loss 0.3561272621154785
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 207 Samples 8000 Step 124 Training Loss 0.35851532220840454
Epoch 207 Validation Loss 0.35603591799736023
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 208 Samples 8000 Step 124 Training Loss 0.3480105996131897
Epoch 208 Validation Loss 0.3564036786556244
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 209 Samples 8000 Step 124 Training Loss 0.3558644652366638
Epoch 209 Validation Loss 0.35595616698265076
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 210 Samples 8000 Step 124 Training Loss 0.3572099804878235
Epoch 210 Validation Loss 0.356099009513855
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 211 Samples 8000 Step 124 Training Loss 0.35551032423973083
Epoch 211 Validation Loss 0.3559248447418213
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25300 that is less than the current step 25502. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25400 that is less than the current step 25603. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25500 that is less than the current step 25703. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25600 that is less than the current step 25804. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25700 that is less than the current step 25905. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25800 that is less than the current step 26006. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25900 that is less than the current step 26107. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26000 that is less than the current step 26207. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26100 that is less than the current step 26308. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26200 that is less than the current step 26409. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26300 that is less than the current step 26510. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26400 that is less than the current step 26611. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 212 Samples 8000 Step 124 Training Loss 0.3530884087085724
Epoch 212 Validation Loss 0.3561669588088989
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [03:37<01:16,  1.06it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 213 Samples 8000 Step 124 Training Loss 0.3576916754245758
Epoch 213 Validation Loss 0.35617807507514954
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 214 Samples 8000 Step 124 Training Loss 0.3550158441066742
Epoch 214 Validation Loss 0.35600560903549194
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 215 Samples 8000 Step 124 Training Loss 0.3572176396846771
Epoch 215 Validation Loss 0.356033593416214
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 216 Samples 8000 Step 124 Training Loss 0.3573474884033203
Epoch 216 Validation Loss 0.35594338178634644
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 217 Samples 8000 Step 124 Training Loss 0.35100510716438293
Epoch 217 Validation Loss 0.35619738698005676
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 218 Samples 8000 Step 124 Training Loss 0.3580344319343567
Epoch 218 Validation Loss 0.3559845983982086
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 219 Samples 8000 Step 124 Training Loss 0.3560594916343689
Epoch 219 Validation Loss 0.35599398612976074
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 220 Samples 8000 Step 124 Training Loss 0.3487735986709595
Epoch 220 Validation Loss 0.35624584555625916
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 221 Samples 8000 Step 124 Training Loss 0.3555392622947693
Epoch 221 Validation Loss 0.3560065031051636
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26600 that is less than the current step 26812. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26700 that is less than the current step 26913. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26800 that is less than the current step 27014. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26900 that is less than the current step 27115. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27000 that is less than the current step 27215. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27100 that is less than the current step 27316. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27200 that is less than the current step 27417. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27300 that is less than the current step 27518. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27400 that is less than the current step 27619. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27500 that is less than the current step 27719. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27600 that is less than the current step 27820. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27700 that is less than the current step 27921. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 222 Samples 8000 Step 124 Training Loss 0.35667601227760315
Epoch 222 Validation Loss 0.3559732139110565
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [03:46<01:13,  1.02s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 223 Samples 8000 Step 124 Training Loss 0.3491975963115692
Epoch 223 Validation Loss 0.3564525544643402
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 224 Samples 8000 Step 124 Training Loss 0.3472224175930023
Epoch 224 Validation Loss 0.3563065230846405
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 225 Samples 8000 Step 124 Training Loss 0.3506906032562256
Epoch 225 Validation Loss 0.35618340969085693
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 226 Samples 8000 Step 124 Training Loss 0.35905614495277405
Epoch 226 Validation Loss 0.35589906573295593
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 227 Samples 8000 Step 124 Training Loss 0.3558792471885681
Epoch 227 Validation Loss 0.356054425239563
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 228 Samples 8000 Step 124 Training Loss 0.35668426752090454
Epoch 228 Validation Loss 0.3560543656349182
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 229 Samples 8000 Step 124 Training Loss 0.34750860929489136
Epoch 229 Validation Loss 0.3562360107898712
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 230 Samples 8000 Step 124 Training Loss 0.3500748872756958
Epoch 230 Validation Loss 0.35615941882133484
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 231 Samples 8000 Step 124 Training Loss 0.3477531373500824
Epoch 231 Validation Loss 0.35651588439941406
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 232 Samples 8000 Step 124 Training Loss 0.35307496786117554
Epoch 232 Validation Loss 0.35595589876174927
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27900 that is less than the current step 28123. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28000 that is less than the current step 28223. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28100 that is less than the current step 28324. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28200 that is less than the current step 28425. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28300 that is less than the current step 28526. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28400 that is less than the current step 28627. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28500 that is less than the current step 28727. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28600 that is less than the current step 28828. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28700 that is less than the current step 28929. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28800 that is less than the current step 29030. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28900 that is less than the current step 29131. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29000 that is less than the current step 29231. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 233 Samples 8000 Step 124 Training Loss 0.346648246049881
Epoch 233 Validation Loss 0.35704857110977173
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [03:56<00:55,  1.11it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 234 Samples 8000 Step 124 Training Loss 0.35602855682373047
Epoch 234 Validation Loss 0.356153666973114
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 235 Samples 8000 Step 124 Training Loss 0.349433034658432
Epoch 235 Validation Loss 0.35610049962997437
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 236 Samples 8000 Step 124 Training Loss 0.3511779010295868
Epoch 236 Validation Loss 0.3564099371433258
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 237 Samples 8000 Step 124 Training Loss 0.3561694324016571
Epoch 237 Validation Loss 0.35586240887641907
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 238 Samples 8000 Step 124 Training Loss 0.35298722982406616
Epoch 238 Validation Loss 0.3560928702354431
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 239 Samples 8000 Step 124 Training Loss 0.36028167605400085
Epoch 239 Validation Loss 0.3560701608657837
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 240 Samples 8000 Step 124 Training Loss 0.3505904972553253
Epoch 240 Validation Loss 0.35597965121269226
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 241 Samples 8000 Step 124 Training Loss 0.35877302289009094
Epoch 241 Validation Loss 0.3559557795524597
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 242 Samples 8000 Step 124 Training Loss 0.35906848311424255
Epoch 242 Validation Loss 0.35622817277908325
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29200 that is less than the current step 29433. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29300 that is less than the current step 29534. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29400 that is less than the current step 29635. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29500 that is less than the current step 29735. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29600 that is less than the current step 29836. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29700 that is less than the current step 29937. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29800 that is less than the current step 30038. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29900 that is less than the current step 30139. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30000 that is less than the current step 30239. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30100 that is less than the current step 30340. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30200 that is less than the current step 30441. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30300 that is less than the current step 30542. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 243 Samples 8000 Step 124 Training Loss 0.36103197932243347
Epoch 243 Validation Loss 0.35596296191215515
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [04:06<00:50,  1.01it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 244 Samples 8000 Step 124 Training Loss 0.35440823435783386
Epoch 244 Validation Loss 0.35596978664398193
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 245 Samples 8000 Step 124 Training Loss 0.34999316930770874
Epoch 245 Validation Loss 0.3561585247516632
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 246 Samples 8000 Step 124 Training Loss 0.3439383804798126
Epoch 246 Validation Loss 0.3568373918533325
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 247 Samples 8000 Step 124 Training Loss 0.3541695475578308
Epoch 247 Validation Loss 0.3558962047100067
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 248 Samples 8000 Step 124 Training Loss 0.3465752899646759
Epoch 248 Validation Loss 0.35665202140808105
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 249 Samples 8000 Step 124 Training Loss 0.3481646478176117
Epoch 249 Validation Loss 0.3561183512210846
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 250 Samples 8000 Step 124 Training Loss 0.35931017994880676
Epoch 250 Validation Loss 0.3560424745082855
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 251 Samples 8000 Step 124 Training Loss 0.35699597001075745
Epoch 251 Validation Loss 0.35601717233657837
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 252 Samples 8000 Step 124 Training Loss 0.3608894944190979
Epoch 252 Validation Loss 0.356014609336853
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30500 that is less than the current step 30743. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30600 that is less than the current step 30844. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30700 that is less than the current step 30945. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30800 that is less than the current step 31046. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30900 that is less than the current step 31147. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31000 that is less than the current step 31247. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31100 that is less than the current step 31348. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31200 that is less than the current step 31449. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31300 that is less than the current step 31550. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31400 that is less than the current step 31651. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31500 that is less than the current step 31751. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 253 Samples 8000 Step 124 Training Loss 0.357334703207016
Epoch 253 Validation Loss 0.35598888993263245
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [04:16<00:39,  1.03it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 254 Samples 8000 Step 124 Training Loss 0.35642123222351074
Epoch 254 Validation Loss 0.35607025027275085
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 255 Samples 8000 Step 124 Training Loss 0.35445913672447205
Epoch 255 Validation Loss 0.3560349941253662
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 256 Samples 8000 Step 124 Training Loss 0.3557316064834595
Epoch 256 Validation Loss 0.35590890049934387
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 257 Samples 8000 Step 124 Training Loss 0.3551066815853119
Epoch 257 Validation Loss 0.3558872938156128
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 258 Samples 8000 Step 124 Training Loss 0.35226839780807495
Epoch 258 Validation Loss 0.35589295625686646
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 259 Samples 8000 Step 124 Training Loss 0.34957072138786316
Epoch 259 Validation Loss 0.3561630845069885
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 260 Samples 8000 Step 124 Training Loss 0.3523521423339844
Epoch 260 Validation Loss 0.3561503291130066
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 261 Samples 8000 Step 124 Training Loss 0.3491173982620239
Epoch 261 Validation Loss 0.3562626540660858
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 262 Samples 8000 Step 124 Training Loss 0.3497486114501953
Epoch 262 Validation Loss 0.3560694754123688
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 263 Samples 8000 Step 124 Training Loss 0.3529071509838104
Epoch 263 Validation Loss 0.356254518032074
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31700 that is less than the current step 31953. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31800 that is less than the current step 32054. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 31900 that is less than the current step 32155. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32000 that is less than the current step 32255. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32100 that is less than the current step 32356. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32200 that is less than the current step 32457. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32300 that is less than the current step 32558. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32400 that is less than the current step 32659. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32500 that is less than the current step 32759. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32600 that is less than the current step 32860. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32700 that is less than the current step 32961. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 32800 that is less than the current step 33062. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 264 Samples 8000 Step 124 Training Loss 0.34641966223716736
Epoch 264 Validation Loss 0.35654765367507935
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [04:27<00:26,  1.10it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 265 Samples 8000 Step 124 Training Loss 0.36018967628479004
Epoch 265 Validation Loss 0.3559052348136902
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 266 Samples 8000 Step 124 Training Loss 0.3468448221683502
Epoch 266 Validation Loss 0.35708126425743103
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 267 Samples 8000 Step 124 Training Loss 0.35769590735435486
Epoch 267 Validation Loss 0.3559279441833496
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 268 Samples 8000 Step 124 Training Loss 0.3516588509082794
Epoch 268 Validation Loss 0.35616910457611084
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 269 Samples 8000 Step 124 Training Loss 0.3522425889968872
Epoch 269 Validation Loss 0.3559555113315582
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 270 Samples 8000 Step 124 Training Loss 0.3543514013290405
Epoch 270 Validation Loss 0.35585150122642517
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 271 Samples 8000 Step 124 Training Loss 0.36197569966316223
Epoch 271 Validation Loss 0.3562585115432739
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 272 Samples 8000 Step 124 Training Loss 0.3516763150691986
Epoch 272 Validation Loss 0.35590094327926636
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 273 Samples 8000 Step 124 Training Loss 0.35731133818626404
Epoch 273 Validation Loss 0.3558684289455414
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33000 that is less than the current step 33263. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33100 that is less than the current step 33364. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33200 that is less than the current step 33465. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33300 that is less than the current step 33566. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33400 that is less than the current step 33667. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33500 that is less than the current step 33767. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33600 that is less than the current step 33868. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33700 that is less than the current step 33969. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33800 that is less than the current step 34070. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 33900 that is less than the current step 34171. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34000 that is less than the current step 34271. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34100 that is less than the current step 34372. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 274 Samples 8000 Step 124 Training Loss 0.3478087782859802
Epoch 274 Validation Loss 0.3562691807746887
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [04:36<00:20,  1.03s/it]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 275 Samples 8000 Step 124 Training Loss 0.35025012493133545
Epoch 275 Validation Loss 0.35592615604400635
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 276 Samples 8000 Step 124 Training Loss 0.3576222062110901
Epoch 276 Validation Loss 0.3559744954109192
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 277 Samples 8000 Step 124 Training Loss 0.3518213629722595
Epoch 277 Validation Loss 0.3560035228729248
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 278 Samples 8000 Step 124 Training Loss 0.3460322618484497
Epoch 278 Validation Loss 0.356864869594574
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 279 Samples 8000 Step 124 Training Loss 0.35052260756492615
Epoch 279 Validation Loss 0.35595449805259705
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 280 Samples 8000 Step 124 Training Loss 0.348147988319397
Epoch 280 Validation Loss 0.3561854958534241
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 281 Samples 8000 Step 124 Training Loss 0.3521179258823395
Epoch 281 Validation Loss 0.3559342920780182
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 282 Samples 8000 Step 124 Training Loss 0.35069575905799866
Epoch 282 Validation Loss 0.35588452219963074
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 283 Samples 8000 Step 124 Training Loss 0.34852373600006104
Epoch 283 Validation Loss 0.35611826181411743
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34300 that is less than the current step 34574. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34400 that is less than the current step 34675. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34500 that is less than the current step 34775. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34600 that is less than the current step 34876. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34700 that is less than the current step 34977. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34800 that is less than the current step 35078. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 34900 that is less than the current step 35179. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35000 that is less than the current step 35279. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35100 that is less than the current step 35380. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35200 that is less than the current step 35481. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35300 that is less than the current step 35582. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35400 that is less than the current step 35683. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 284 Samples 8000 Step 124 Training Loss 0.35725268721580505
Epoch 284 Validation Loss 0.3559619188308716
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [04:47<00:08,  1.05it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 285 Samples 8000 Step 124 Training Loss 0.3576183021068573
Epoch 285 Validation Loss 0.35598620772361755
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 286 Samples 8000 Step 124 Training Loss 0.34951889514923096
Epoch 286 Validation Loss 0.356050580739975
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 287 Samples 8000 Step 124 Training Loss 0.34888535737991333
Epoch 287 Validation Loss 0.3563361167907715
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 288 Samples 8000 Step 124 Training Loss 0.3577757477760315
Epoch 288 Validation Loss 0.3558226525783539
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 289 Samples 8000 Step 124 Training Loss 0.3463551998138428
Epoch 289 Validation Loss 0.3564818501472473
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 290 Samples 8000 Step 124 Training Loss 0.3535604476928711
Epoch 290 Validation Loss 0.35592520236968994
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 291 Samples 8000 Step 124 Training Loss 0.35606715083122253
Epoch 291 Validation Loss 0.3558148443698883
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 292 Samples 8000 Step 124 Training Loss 0.34589362144470215
Epoch 292 Validation Loss 0.3564995527267456
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 293 Samples 8000 Step 124 Training Loss 0.3552667796611786
Epoch 293 Validation Loss 0.3559652864933014
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35600 that is less than the current step 35884. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35700 that is less than the current step 35985. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35800 that is less than the current step 36086. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 35900 that is less than the current step 36187. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36000 that is less than the current step 36287. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36100 that is less than the current step 36388. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36200 that is less than the current step 36489. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36300 that is less than the current step 36590. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36400 that is less than the current step 36691. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36500 that is less than the current step 36791. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36600 that is less than the current step 36892. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 294 Samples 8000 Step 124 Training Loss 0.35062986612319946
Epoch 294 Validation Loss 0.3561438024044037
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [04:56<00:00,  1.01it/s]
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 295 Samples 8000 Step 124 Training Loss 0.345394104719162
Epoch 295 Validation Loss 0.35631003975868225
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 296 Samples 8000 Step 124 Training Loss 0.3568382263183594
Epoch 296 Validation Loss 0.355913370847702
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 297 Samples 8000 Step 124 Training Loss 0.33848026394844055
Epoch 297 Validation Loss 0.35731711983680725
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 298 Samples 8000 Step 124 Training Loss 0.351474404335022
Epoch 298 Validation Loss 0.3562164902687073
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 299 Samples 8000 Step 124 Training Loss 0.35005316138267517
Epoch 299 Validation Loss 0.3562103509902954
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Cache key blocks.0.attn.pattern not found. Available keys: ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k']
Vocab size too small (2) for prefix matching
Epoch 300 Samples 8000 Step 124 Training Loss 0.35042884945869446
Epoch 300 Validation Loss 0.3561268150806427
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36700 that is less than the current step 36993. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36800 that is less than the current step 37094. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 36900 that is less than the current step 37195. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37000 that is less than the current step 37295. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37100 that is less than the current step 37396. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37200 that is less than the current step 37497. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37300 that is less than the current step 37598. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37400 that is less than the current step 37699. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 37500 that is less than the current step 37799. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
DEBUG

Model_1
/Users/sbhandari/Documents/GitHub/Vivekafork/toy_transformer/DEBUG

Model_1
DEBUG

Model_1
DEBUG

Model_1
DEBUG

Model_1
DEBUG

Model_1
Accuracy: 100.00 %

Model_21
Accuracy: 100.00 %

Model_41
Accuracy: 100.00 %

Model_61
Accuracy: 100.00 %

Model_81
Accuracy: 100.00 %

Model_101
Accuracy: 100.00 %

Model_121
Accuracy: 100.00 %

Model_141
Accuracy: 100.00 %

Model_161
Accuracy: 100.00 %

Model_181
Accuracy: 100.00 %

Model_201
Accuracy: 100.00 %

Model_221
Accuracy: 100.00 %

Model_241
Accuracy: 100.00 %

Model_261
Accuracy: 100.00 %

Model_281
Accuracy: 100.00 %

Model_301
DEBUG
B||M = KL(Markov || Model), M||B = KL(Model || Markov)

DEBUG
B||M = KL(Markov || Model), M||B = KL(Model || Markov)

DEBUG
B||M = KL(Markov || Model), M||B = KL(Model || Markov)

Model 5: B||M - 0.117, M||B - 1.248
Model 10: B||M - 0.116, M||B - 1.182
Model 15: B||M - 0.115, M||B - 1.215
Model 20: B||M - 0.114, M||B - 1.125
Model 25: B||M - 0.113, M||B - 1.079
Model 30: B||M - 0.111, M||B - 1.176
Model 35: B||M - 0.108, M||B - 1.132
Model 40: B||M - 0.105, M||B - 1.063
Model 45: B||M - 0.101, M||B - 0.931
Model 50: B||M - 0.097, M||B - 0.808
Model 55: B||M - 0.084, M||B - 0.824
Model 60: B||M - 0.107, M||B - 1.195
Model 65: B||M - 0.066, M||B - 0.698
Model 70: B||M - 0.057, M||B - 0.458
Model 75: B||M - 0.054, M||B - 0.370
Model 80: B||M - 0.054, M||B - 0.244
Model 85: B||M - 0.047, M||B - 0.196
Model 90: B||M - 0.049, M||B - 0.140
Model 95: B||M - 0.048, M||B - 0.128
Model 100: B||M - 0.049, M||B - 0.137
Model 105: B||M - 0.054, M||B - 0.151
Model 110: B||M - 0.053, M||B - 0.123
Model 115: B||M - 0.052, M||B - 0.125
Model 120: B||M - 0.054, M||B - 0.118
Model 125: B||M - 0.054, M||B - 0.118
Model 130: B||M - 0.053, M||B - 0.119
Model 135: B||M - 0.053, M||B - 0.116
Model 140: B||M - 0.056, M||B - 0.107
Model 145: B||M - 0.054, M||B - 0.110
Model 150: B||M - 0.054, M||B - 0.110
Model 155: B||M - 0.054, M||B - 0.112
Model 160: B||M - 0.053, M||B - 0.109
Model 165: B||M - 0.054, M||B - 0.110
Model 170: B||M - 0.054, M||B - 0.110
Model 175: B||M - 0.054, M||B - 0.109
Model 180: B||M - 0.053, M||B - 0.105
Model 185: B||M - 0.053, M||B - 0.106
Model 190: B||M - 0.052, M||B - 0.107
Model 195: B||M - 0.053, M||B - 0.110
Model 200: B||M - 0.054, M||B - 0.102
Model 205: B||M - 0.053, M||B - 0.102
Model 210: B||M - 0.053, M||B - 0.102
Model 215: B||M - 0.052, M||B - 0.102
Model 220: B||M - 0.053, M||B - 0.109
Model 225: B||M - 0.053, M||B - 0.106
Model 230: B||M - 0.052, M||B - 0.106
Model 235: B||M - 0.052, M||B - 0.105
Model 240: B||M - 0.052, M||B - 0.104
Model 245: B||M - 0.051, M||B - 0.105
Model 250: B||M - 0.051, M||B - 0.102
Model 255: B||M - 0.051, M||B - 0.105
Model 260: B||M - 0.051, M||B - 0.105
Model 265: B||M - 0.050, M||B - 0.102
Model 270: B||M - 0.052, M||B - 0.103
Model 275: B||M - 0.050, M||B - 0.105
Model 280: B||M - 0.050, M||B - 0.103
Model 285: B||M - 0.050, M||B - 0.101
Model 290: B||M - 0.050, M||B - 0.104
Model 295: B||M - 0.050, M||B - 0.104
[34m[1mwandb[0m: [32m[41mERROR[0m The nbformat package was not found. It is required to save notebook history.
